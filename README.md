# üö≤ **JeVelibererLaData ‚Äì V√©lib Analytics Platform**  
### *Pipeline complet : 250 Go JSON.gz ‚Üí ETL Python ‚Üí PostgreSQL ‚Üí API FastAPI ‚Üí Vue analytique des trajets*

---

## üìå **Description g√©n√©rale**

**JeVelibererLaData** est un projet complet de **Data Engineering + API Design**, dont l‚Äôobjectif est d‚Äôextraire, transformer et analyser les donn√©es V√©lib issues d‚Äôune source JSON priv√©e (environ **250 Go** de fichiers `.json.gz`).

Le projet inclut :

- Un pipeline **ETL** robuste (Python + Jupyter)
- Un stockage mod√©lis√© en **PostgreSQL**
- Une API **FastAPI** exposant :
  - les **dimensions** (CRUD complet : stations, v√©los)
  - les **faits** (lecture analytique)
  - une **vue V_TRAJETS** permettant d‚Äôanalyser les d√©placements
- Plusieurs **visualisations** : ERD, pipeline, swagger, architecture
- Un d√©p√¥t Git structur√© et pr√™t pour production

Ce projet d√©montre des comp√©tences en :
‚úî Ing√©nierie Data  
‚úî Mod√©lisation SQL  
‚úî Traitement de tr√®s gros volumes  
‚úî D√©veloppement d‚ÄôAPI  
‚úî Documentation technique  

---

# üèóÔ∏è **Architecture globale du pipeline**
```
                +-------------------------+
                |  Fichiers V√©lib JSON.gz |
                |     (250 Go bruts)      |
                +------------+------------+
                             |
                             | 1. Extraction / Lecture
                             v
                   +--------------------+
                   |  ETL Python        |
                   | (Jupyter Notebook) |
                   +---------+----------+
                             |
                             | 2. Transformation
                             v
                     +------------------+
                     | PostgreSQL (DB)  |
                     | Dimensions/Faits |
                     +---------+--------+
                               |
                               | 3. Exposition API REST
                               v
                       +----------------+
                       |    FastAPI     |
                       |  (Uvicorn)     |
                       +-------+--------+
                               |
                               | 4. Usage / Analyse
                               v
                    +------------------------------+
                    | Swagger UI / Clients externes |
                    +------------------------------+
```
---

# üìö **Technologies utilis√©es**

### üêç **Python**
- Jupyter Notebook (ETL)
- gzip / json
- pandas (optionnel)
- FastAPI
- Uvicorn  
- asyncpg ou psycopg2

### üóÉÔ∏è **Base de donn√©es**
- PostgreSQL  
- Mod√®le dimensionnel + faits  
- Vue analytique `V_TRAJETS`

### üåê **API Backend**
- FastAPI  
- OpenAPI 3.1  
- Validation Pydantic  

---

# üìÅ **Structure du repository**

```
JeVelibererLaData/
‚îÇ
‚îú‚îÄ‚îÄ app/
‚îÇ ‚îú‚îÄ‚îÄ main.py # Point d‚Äôentr√©e FastAPI
‚îÇ ‚îú‚îÄ‚îÄ models.py # Mod√®les SQLAlchemy / Pydantic
‚îÇ ‚îú‚îÄ‚îÄ etl.py # Pipeline ETL
‚îÇ ‚îú‚îÄ‚îÄ database.py # Connexion PostgreSQL
‚îÇ ‚îú‚îÄ‚îÄ routers/ # (optionnel)
‚îÇ ‚îî‚îÄ‚îÄ init.py
‚îÇ
‚îú‚îÄ‚îÄ data/ # Non versionn√© (poids √©norme)
‚îÇ ‚îú‚îÄ‚îÄ progress.json
‚îÇ ‚îú‚îÄ‚îÄ data_import_errors.log
‚îÇ
‚îú‚îÄ‚îÄ image/ # Captures d'√©cran
‚îÇ ‚îú‚îÄ‚îÄ swagger.png
‚îÇ ‚îú‚îÄ‚îÄ pipeline.png
‚îÇ ‚îú‚îÄ‚îÄ erd.png
‚îÇ ‚îî‚îÄ‚îÄ api_structure.png
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ LICENSE
```


---

# üóÑÔ∏è **Mod√®le de donn√©es PostgreSQL**

### üìå Tables de **dimension**
- `station`  
- `velo`  
- `etat_station`  
- `localisation_velo`  
- `snapshot`  

### üìå Vue analytique
- `V_TRAJETS`  
Reconstitution des trajets en comparant les changements de localisation des v√©los.

---

# üìò **ERD (Diagramme relationnel)**
---

# üîÑ Pipeline ETL ‚Äì Architecture d√©taill√©e

Le pipeline d‚Äôingestion traite **250 Go de fichiers JSON.gz** provenant des snapshots V√©lib.  
Objectifs : *lecture ‚Üí parsing ‚Üí transformation ‚Üí insertion incr√©mentale ‚Üí r√©silience ‚Üí g√©n√©ration des vues analytiques*.

---

## 1Ô∏è‚É£ **Lecture & Extraction**

- Parcours r√©cursif du dossier source contenant les fichiers `.json.gz`
- D√©tection automatique du format :
  - lecture directe si `.json`
  - d√©compression via `gzip` si `.gz`
- Gestion d‚Äôun fichier `progress.json` pour :
  - savoir quels fichiers ont d√©j√† √©t√© trait√©s
  - permettre la reprise apr√®s crash
  - √©viter les doublons et retraitements

---

## 2Ô∏è‚É£ **Parsing & Validation**

Chaque fichier contient un snapshot complet V√©lib.  
Le pipeline extrait et valide trois grandes familles d‚Äôentit√©s :

### **üÖê Station**
- station_code  
- g√©olocalisation (lat/lon)  
- capacit√© totale  
- type de station  

### **üÖë V√©lo**
- velo_name  
- type (m√©canique / √©lectrique)  
- statut  

### **üÖí √âtat & Localisation**
- √©tat temps r√©el d‚Äôune station  
- localisation d‚Äôun v√©lo  
- timestamp exact du snapshot  

Toute erreur de format est automatiquement envoy√©e dans :
```
data/data_import_errors.log
```

> *(ajoutez votre image dans `/image/erd.png`)*


---

## 3Ô∏è‚É£ **Transformation & Normalisation**

- Nettoyage des champs  
- Renommage coh√©rent  
- Transformation des types Python ‚Üí PostgreSQL  
- Enrichissement :
  - g√©n√©ration de `snapshot_id`
  - normalisation code station / bikeStatus / state

---

## 4Ô∏è‚É£ **Buffers m√©moire (Batch Processing)**

Pour optimiser les performances, le pipeline utilise des **buffers temporaires** :

- `station_buffer`
- `velo_buffer`
- `etat_station_buffer`
- `localisation_velo_buffer`

Chaque buffer est vid√© en base via **Bulk Insert**.

---

## 5Ô∏è‚É£ **Chargement en base (PostgreSQL)**

Insertion optimis√©e :

- **UPSERT** pour les dimensions station / v√©lo
- **INSERT batch** pour :
  - `etat_station`
  - `localisation_velo`
  - `snapshot`

Gestion transactionnelle compl√®te :
- `commit` sur succ√®s  
- `rollback` si erreur  

---

## 6Ô∏è‚É£ **R√©silience & Reprise**

Composant cl√© : `progress.json`

Il permet :

| Fonction | Description |
|---------|-------------|
| Suivi | Liste des fichiers d√©j√† trait√©s |
| Reprise | Red√©marrer apr√®s crash |
| Coh√©rence | Emp√™cher reprocessing d'un fichier |
| Reconstruction | R√©cup√©rer le dernier snapshot_id |

---

## 7Ô∏è‚É£ **Sortie : Base pr√™te pour Analytics**

Une fois tous les fichiers trait√©s, la base contient :

### **Tables brutes**
- `station`
- `velo`
- `snapshot`
- `etat_station`
- `localisation_velo`

### **Vue analytique reconstruite**
- `V_TRAJETS`  
Reconstitue les trajets en comparant la localisation d‚Äôun v√©lo entre deux snapshots cons√©cutifs.

Exemples de m√©triques disponibles :

- Liste des trajets d‚Äôun v√©lo
- Temps moyen d‚Äôun trajet
- Top stations d√©part
- Top stations arriv√©e
- Nombre de stations visit√©es par v√©lo
- V√©los les plus utilis√©s (top N)

---

# üìä **Sch√©ma visuel du Pipeline (Image)**

Ajoutez l‚Äôimage :

```md
![Pipeline](image/pipeline.png)


```md
![ERD](image/erd.png)
